---
title: "SVM with Multiple Classes"
output: html_document
---


Use `ROCR` package to produce ROC Curves with a custom short function and load all `svm` packages

```{r, results='hide'}
library(e1071)
```

Simulate the data and the data frame

```{r}
set.seed(1)
x=matrix(rnorm(200*2), ncol=2)

# To seperate X values in non-linear way
x[1:100,] <- x[1:100,] + 2
x[101:150,] <- x[101:150,] - 2

y <- c(rep(1,150), rep(2,50))
dat <- data.frame(x=x, y=as.factor(y)) # only works with a data frame
train <- sample(200, 100) # 100 samples between 0 to 200, good way to get the training
```


If the response is a factor containing more than two levels, then the `svm()` function will perform multi-class classification using the one-versus-one approach. We explore that setting here by generating a third class of observations.

```{r}
set.seed(1)
x=rbind(x, matrix(rnorm(50*2), ncol=2))
y=c(y, rep(0,50))
x[y==0,2]=x[y==0,2]+2
dat=data.frame(x=x, y=as.factor(y))
par(mfrow=c(1,1))
plot(x,col=(y+1))
```

Just multiple data points of 4 in different colors.

To fit an SVM to the data

```{r}
svmfit <- svm(y~., data=dat, kernel="radial", cost=10, gamma=1)
plot(svmfit, dat)
```

We can use ROC to test which one is good if we use different gamma.

We should be able to then predict it.

