---
title: "Support Vector Machine"
output: html_document
---

Load all `svm` packages

```{r}
library(e1071)
```

To fit an SVM using a non-linear kernel, we use `svm()` function. We use `kernel="polynomail"` for a polynomial kernel and use `kernel="radial"`

We specify `degree` to specifiy a degree for polynomail kernel.

We specifiy `gamma` $\gamma$ for a radial kernel.

Simulate data for Support Vector Machine with a non-linear boundary.

```{r}
set.seed(1)
x=matrix(rnorm(200*2), ncol=2)

# To seperate X values in non-linear way
x[1:100,] <- x[1:100,] + 2
x[101:150,] <- x[101:150,] - 2

y <- c(rep(1,150), rep(2,50))
dat <- data.frame(x=x, y=as.factor(y)) # only works with a data frame
```


Plotting the data sees the class boundary is indeed non-linear.

Non-linear works with Support vector machine. May not work with Support Vector Classifier.

```{r}
plot(x, col=y) # y is supposed to be a factor
```

The data is randomly split into training and testing groups. We fit the training data using the `svm()` with a radial kernel of $\gamma=1$. Why keep `gamma=1` and `cost=1`.

```{r}
train <- sample(200, 100) # 100 samples between 0 to 200
svmfit <- svm(y~., data=dat[train,], kernel="radial",  gamma=1, cost=1)
plot(svmfit, dat[train,])
```

Seperates classifications by regions instead of a boundary line.

We can see from the figure that there are a fair number of training errors in this SVM fit.

The `summary()` function can be used to obtain some information about the SVM fit.

```{r}
summary(svmfit)
```

If we increase the value of cost, we can reduce the number of training errors.

However, this comes at the price of a more irregular decision boundary that seems to be at risk of overfitting the data.

```{r}
svmfit <- svm(y~., data=dat[train,], kernel="radial", gamma=1, cost=1e5)
plot(svmfit, dat[train,])
```

We can perform cross-valiation using `tune()` to select the best choice of $\gamma$ and `cost` for a SVM with a radial kernel.

Is radial kernel for support vector machine.

```{r}
set.seed(1)
tune.out <- tune(svm, y~., data=dat[train,], kernel="radial", 
                 ranges=list(cost=c(0.1,1,10,100,1000), gamma=c(0.5,1,2,3,4)))
summary(tune.out)
```

The best choice of parameters involves `cost=1` and `gamma=2`.

We can view the test set predictions for this model by applying the `predict()` function.

Do this with the subset the dataframe `dat` using `-train` as an index set.

```{r}
# -train is the rest of the 100 data for testing
table(true=dat[-train,"y"], 
      pred=predict(tune.out$best.model, newdata=dat[-train,]))
```

39% of test observation are misclassified by this SVM.