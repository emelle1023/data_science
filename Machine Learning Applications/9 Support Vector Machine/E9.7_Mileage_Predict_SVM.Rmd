---
title: "SVM Prediction of high or low gas mileage"
output: html_document
---

## Synopsis

Use support vector approaches in order to predict whether a given car gets high or low gas mileage based on the `Auto` data set.

## Analysis


### Create data for analysis

Create a binary variable that takes on a 1 for cars with gas mileage above the median, and a 0 for cars with gas mileage below the median.

```{r}
library(ISLR)
gas.med = median(Auto$mpg)
new.var = ifelse(Auto$mpg > gas.med, 1, 0) # just one line to 
Auto$mpglevel = as.factor(new.var) # still factor y
```

### Fit Support classifier with different value of `cost`

SVM library loading

```{r}
library(e1071)
```

To apply different costs for cross-validation errors

```{r svm, cache=TRUE}
set.seed(3255)
tune.out = tune(svm, mpglevel ~ ., data = Auto, kernel = "linear", 
    ranges = list(cost = c(0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
```

The corss-validation eroor is minimised in `0.01282051` for `cost=1`. We didn't have any training or testing, we ran the entire data set.


### SVM with radial and polynomial basis kernel with different `gamma` and `degree` and `cost`

#### Polynomial SVM

We specifically use only polynomial for a range of costs and degrees. We will need different degrees as it is a polynomial.

```{r poly, cache=TRUE}
set.seed(21)
tune.out = tune(svm, mpglevel ~ ., data = Auto, kernel = "polynomial", 
                ranges = list(cost = c(0.1, 1, 5, 10), 
                              degree = c(2, 3, 4)))
summary(tune.out)
```

The lowest cross-validation error is obtained for `cost=10` and `degree=2`. 

`Cost` seems to be `10` and we this time only use the entire dataset. We shouldn't be running the model using the entire dataset.

#### Kernel SVM

Still need to apply `cost` and `gamma`

```{r ker, cache=TRUE}
set.seed(463)
tune.out = tune(svm, mpglevel ~ ., data = Auto, kernel = "radial", 
                ranges = list(cost = c(0.1, 1, 5, 10), 
                              gamma = c(0.01, 0.1, 1, 5, 10, 100)))
summary(tune.out)
```

Finally, for radial basis kernel, `cost=10` and `gamma=0.01`.

Should we use kernel or polynomial?

### Compairsion using plots of models linear, polynomial and radial.

```{r models, cache=TRUE}
svm.linear = svm(mpglevel ~ ., data = Auto, kernel = "linear", cost = 1)
svm.poly = svm(mpglevel ~ ., data = Auto, kernel = "polynomial", cost = 10, 
    degree = 2)
svm.radial = svm(mpglevel ~ ., data = Auto, kernel = "radial", cost = 10, gamma = 0.01)
```

```{r plotpairs, cache=TRUE}
library(knitr)
opts_chunk$set(out.extra='style="display:block; margin: auto"', fig.align="center")

# Plot each variable
plotpairs = function(fit) {
    par(mfrow = c(2,2))
    for (name in names(Auto)[!(names(Auto) %in% c("mpg", "mpglevel", "name"))]) {
        plot(fit, Auto, as.formula(paste("mpg~", name, sep = "")))
    }
}
```

#### Linear plots for most variables

```{r}
plotpairs(svm.linear)
```

#### Polynomial plots for most variables

```{r}
plotpairs(svm.poly)
```

#### Radial plots for most variables

```{r}
plotpairs(svm.radial)
```


## Conclusion

Our SVM models classify each of the variables for mileage. It doesn't seem both radial and polynomial work at all as every variable will contribute to a mileage greater than median.

Perhaps we need to deal with all variables at all once.

The linear model is not accurate though.

