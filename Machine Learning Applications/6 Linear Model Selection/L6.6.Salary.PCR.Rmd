---
title: "Predict Salary using Principle Components Regression"
output: html_document
---

## Synopsis

We will predict baseball players' salary using Lasso.

## Analysis

Principal components regression (PCR) can be performed using the `pcr()`, which is part of the `pls` library.  Again, ensure that the missing values have been removed from the data.

### Remove Missing data

```{r}
library(ISLR)
Hitters=na.omit(Hitters)
```


### Manage dataset in matrix for Lasso

```{r}
x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
```

### Generate training and testing data for Lasso

```{r}
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
```

We won't be needing a matrix unlike Lasso.

### Perform PCR

```{r, message=FALSE, warning=FALSE}
library(pls)
set.seed(2)
pcr.fit=pcr(Salary~., data=Hitters,scale=TRUE,validation="CV")
```

Setting `scale=TRUE` has the effect of standardizing each predictor. Prior to generating the principal components, so that the scale on which each variable is measured will not have an effect.

Setting `validation="CV"` causes `pcr()` to compute the ten-fold cross-validation error for each possible value of M (The number of principle components used).

### Summary of result fit

```{r}
summary(pcr.fit)
```

The CV score is provided for each possible number of components, ranging `from M = 0` onwards.

Note that `pcr()` reports the root mean squared error; in order to obtain the usual MSE, we must square this quantity.

For instance, a root mean squared error of 352.8 corresponds to an $MSE$ of 352.82 = 124,468.


### Plot cross-validation scores

Plot the cross-validation scores using the `validationplot()` validation function. Using `val.type="MSEP"` will cause the cross-validation MSE to be plot() plotted.

```{r}
validationplot(pcr.fit,val.type="MSEP")
```

We see that the smallest cross-validation error occurs when M = 16 components are used. This is barely fewer than M = 19, which amounts to simply performing least squares, because when all of the components are used in PCR no dimension reduction occurs.

However, from the plot we also see that the cross-validation error is roughly the same when only one component is included in the model. This suggests that a model that uses just a small number of components might suffice.



Briefly, we can think of this as the amount of information about the predictors or the response that is captured using M principal components.

For example, setting M = 1 only captures 38.31% of all the variance, or information, in the predictors. In contrast, using M = 6 increases the value to 88.63%. If we were to use all M = p = 19 components, this would increase to 100%.


### PCR Test set

```{r}
set.seed(1)
pcr.fit=pcr(Salary~., data=Hitters,subset=train,scale=TRUE, validation="CV")
validationplot(pcr.fit,val.type="MSEP")
```

Now we find that the lowest cross-validation error occurs when M = 7 component are used.

### Test MSE

```{r}
pcr.pred=predict(pcr.fit,x[test,],ncomp=7)
mean((pcr.pred-y.test)^2)
```

This test set MSE is competitive with the results obtained using ridge regression
and the lasso. However, as a result of the way PCR is implemented, the final model is more difficult to interpret because it does not perform any kind of variable selection or even directly produce coefficient estimates.


### PCR Full Data set

We fit PCR on the full data set, using M = 7, the number of components identified by cross-validation.

```{r}
pcr.fit=pcr(y~x,scale=TRUE,ncomp=7)
summary(pcr.fit)
```
