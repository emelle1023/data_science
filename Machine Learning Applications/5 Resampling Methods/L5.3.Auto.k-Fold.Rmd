---
title: "Auto fitting with k-Fold Cross-Validation"
output: html_document
---

## Synopsis

To use k-Fold Cross Validation to analyse and test and Auto dataset and compare it with Validation set approach and Leave-One-out Cross-Validation Approach.

## Analysis

We use *k = 10*, a common choice for *k*. We set a random seed and initialize a vector in which we will store the CV errors corresponding to the polynomial fits of orders one to ten.

```{r}
library(ISLR)
library(boot)

set.seed(17)
cv.error.10=rep(0,10)
for (i in 1:10){
 glm.fit=glm(mpg~poly(horsepower,i),data=Auto)
 cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]
 }
cv.error.10
```

Notice that the computation time is much shorter than that of LOOCV.

In principle, the computation time for LOOCV for a least squares linear
model should be faster than for k-fold CV, due to the availability of the formula for LOOCV. However, unfortunately the `cv.glm()` function
does not make use of this formula.

## Conclustion

We still see little evidence that using cubic or higher-order polynomial terms leads to lower test error than simply using a quadratic fit.

The two numbers associated with `delta` are essentially the same when LOOCV is performed. When we instead perform k-fold CV, then the two numbers associated with `delta` differ slightly.

The first is the standard k-fold CV estimate. The second is a bias-corrected version.

On this data set, the two estimates are very similar to each other.
