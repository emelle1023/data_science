---
title: "Housing Prices Prediction"
output: html_document
---

## Synopsis

To fit a regression Tree Boston housing prices and a Regression Tree


## Analysis

### Load Regression library

```{r}
library (tree)
```

### Run Regression Tree

To create a training set and fit the tree with it.

```{r}
library(MASS)
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston)/2) # random pick 50% of the entire dataset

# apply Regression tree to the training dataset
tree.boston <- tree(medv~., Boston, subset=train)
summary(tree.boston)
```

Only three of the variables have been used in constructing the tree, `lstat`, `rm` and `dis`.

The deviance is simply the sum of squared errors for the tree.

### Plot Regression Tree

```{r}
plot(tree.boston)
text(tree.boston,pretty=0)
```

The variable `lstat` measures the percentage of individuals with lower socioeconomic status. The tree indicates that lower values of lstat correspond to more expensive houses.

An example to see this is...

The tree predicts a median house price of `$46,400` for larger homes in suburbs in which residents have high socioeconomic status `(rm>=7.437 and lstat<9.715)`.


### Worth to prune the tree for better performance (Cross-validation)

```{r}
cv.boston <- cv.tree(tree.boston) 
plot(cv.boston$size, cv.boston$dev, type='b')
```

In this case, the most complex tree is selected by cross-validation. But I reckon maybe 4 nodes will do. but overall, we should prune it anyway. But why not 8.

### Prune the tree

```{r}
prune.boston <- prune.tree(tree.boston, best=5) # can do 4 nodes
plot(prune.boston)
text(prune.boston, pretty=0)
```

### Cross-validatiion on test set using Unpruned tree

In keeping with the cross-validation results, we use the unpruned tree to make predictions on the test set.

```{r}
yhat <- predict(tree.boston, newdata=Boston[-train,])
boston.test <- Boston[-train,"medv"]

# Testing the error 
plot(yhat, boston.test)
abline(0,1)

mean((yhat-boston.test)^2)
```

In other words, the test set MSE associated with the regression tree is `25.05`. The square root of the MSE is therefore around `5.005`, indicating that this model leads to test predictions that are within around `$5,005` of the true median home value for the suburb.